# ğŸš€ COMP2850 Portfolio - Quick Setup Guide

**Time to complete**: 30 minutes  
**Goal**: Set up all required files with templates ready to fill in

---

## ğŸ“ Step 1: Create Directory Structure (5 min)

In your project root, run:

```bash
# Create all required directories
mkdir -p evidence/screenshots
mkdir -p evidence/pilot-notes

# Or manually create:
# YourProject/
# â”œâ”€â”€ protocol-tasks.md
# â”œâ”€â”€ findings-table.csv
# â”œâ”€â”€ metrics.csv (will be generated by Logger.kt)
# â”œâ”€â”€ implementation-diffs.md
# â”œâ”€â”€ verification.csv
# â””â”€â”€ evidence/
#     â”œâ”€â”€ README.md
#     â”œâ”€â”€ screenshots/
#     â”‚   â””â”€â”€ annotations.csv
#     â””â”€â”€ pilot-notes/
#         â”œâ”€â”€ P1-notes.md
#         â”œâ”€â”€ P2-notes.md
#         â””â”€â”€ consent-log.md
```

---

## ğŸ“ Step 2: Copy Template Files (10 min)

### Option A: Download from Claude Artifacts (Recommended)
I've generated all templates in artifacts above. Click each artifact and save as:

1. **protocol-tasks.md** â†’ Save to project root
2. **findings-table.csv** â†’ Save to project root
3. **metrics.csv** â†’ Will be auto-generated by Logger.kt in `data/` folder
4. **implementation-diffs.md** â†’ Save to project root
5. **verification.csv** â†’ Save to project root
6. **evidence/README.md** â†’ Save to `evidence/`
7. **evidence/screenshots/annotations.csv** â†’ Save to `evidence/screenshots/`
8. **evidence/pilot-notes/P1-notes.md** â†’ Save to `evidence/pilot-notes/` (duplicate for P2-P4)
9. **evidence/pilot-notes/consent-log.md** â†’ Save to `evidence/pilot-notes/`
10. **package-submission.sh** â†’ Save to project root (for final packaging)

### Option B: Copy from this conversation
Scroll up and copy each artifact's content into the corresponding file.

---

## âœï¸ Step 3: Customize Templates (5 min)

**Find and replace these placeholders** in ALL files:

- `[Your Name]` â†’ Your actual name
- `[Your ID]` â†’ Your student ID
- `[DD/MM/YYYY]` â†’ Submission date (end of Week 10)
- `[your.email@university.edu]` â†’ Your university email

**Quick search-and-replace command** (if you're on Mac/Linux):

```bash
# Replace placeholders (run in project root)
find . -type f \( -name "*.md" -o -name "*.csv" \) -exec sed -i '' 's/\[Your Name\]/John Smith/g' {} +
find . -type f \( -name "*.md" -o -name "*.csv" \) -exec sed -i '' 's/\[Your ID\]/201234567/g' {} +
find . -type f \( -name "*.md" -o -name "*.csv" \) -exec sed -i '' 's/\[DD\/MM\/YYYY\]/30\/11\/2025/g' {} +
```

(For Windows, use PowerShell or manually find-replace in your editor)

---

## ğŸ› ï¸ Step 4: Set Up Logger.kt (10 min)

### 4.1: Create Logger File

Copy the Logger code from **Week 9 Lab 1** (lines 1073-1158 in the assessment docs):

```bash
# Create utils directory if it doesn't exist
mkdir -p src/main/kotlin/utils
```

Create `src/main/kotlin/utils/Logger.kt` with this content:

```kotlin
package utils

import java.io.File
import java.time.Instant

data class LogEntry(
    val ts: String,
    val sessionId: String,
    val requestId: String,
    val taskCode: String,
    val step: String,
    val outcome: String,
    val ms: Long,
    val httpStatus: Int,
    val jsMode: String
)

object Logger {
    private val csvFile = File("data/metrics.csv")
    
    init {
        // Create data directory if it doesn't exist
        csvFile.parentFile?.mkdirs()
        
        // Write CSV header if file doesn't exist
        if (!csvFile.exists()) {
            csvFile.writeText("ts_iso,session_id,request_id,task_code,step,outcome,ms,http_status,js_mode\n")
        }
    }
    
    fun log(
        sessionId: String,
        requestId: String,
        taskCode: String,
        step: String = "",
        outcome: String = "",
        ms: Long = 0,
        httpStatus: Int = 200,
        jsMode: String = "on"
    ) {
        val timestamp = Instant.now().toString()
        val line = "$timestamp,$sessionId,$requestId,$taskCode,$step,$outcome,$ms,$httpStatus,$jsMode\n"
        csvFile.appendText(line)
    }
}
```

### 4.2: Integrate Logger in Routes

In `src/main/kotlin/routes/TaskRoutes.kt`, add logging calls:

```kotlin
import utils.Logger

// Example: Log successful task creation
post("/tasks") {
    val sessionId = call.request.cookies["sid"] ?: "unknown"
    val requestId = "req_${System.currentTimeMillis()}"
    
    // Your existing task creation logic...
    
    Logger.log(
        sessionId = sessionId,
        requestId = requestId,
        taskCode = "T1_add",
        step = "success",
        outcome = "",
        ms = durationMs,  // Measure this with timed() function
        httpStatus = 200,
        jsMode = if (isHtmxRequest) "on" else "off"
    )
    
    // Respond...
}
```

### 4.3: Test Logger

```bash
# Run your app
./gradlew run

# In browser console, set session ID:
document.cookie = "sid=TEST_abc123; path=/";

# Add a task, then check:
cat data/metrics.csv
# Should see a new line with TEST_abc123 session ID
```

---

## âœ… Step 5: Verify Setup (5 min)

Run this checklist:

```bash
# Check all files exist
ls protocol-tasks.md findings-table.csv implementation-diffs.md verification.csv
ls evidence/README.md evidence/screenshots/annotations.csv
ls evidence/pilot-notes/consent-log.md

# Check Logger works
./gradlew run
# (Open app, do an action, check data/metrics.csv)

# Check directory structure
tree -L 3
# Should match the structure at top of this guide
```

---

## ğŸ“‹ What to Fill In Next

Now that templates are set up, you need to:

### Week 9 Lab 1 (Planning):
1. **protocol-tasks.md**: 
   - Review your Week 6 Job Stories
   - Design 4-5 evaluation tasks
   - Calculate target times (your expert time Ã— 2)

### Week 9 Lab 2 (Run Pilots):
1. Recruit 2-4 participants
2. Set session cookies (`sid=P1_xxxx` before each pilot)
3. Record pilot notes in `evidence/pilot-notes/P#-notes.md`
4. Logger auto-generates `data/metrics.csv`

### Week 10 Lab 1 (Analyze):
1. Analyze `data/metrics.csv` (use provided Kotlin script or manual)
2. Fill in `findings-table.csv` with priority scores
3. Select top 3 findings to fix

### Week 10 Lab 2 (Fix & Verify):
1. Implement fixes, document in `implementation-diffs.md`
2. Complete `verification.csv` (20 WCAG checks + before/after)
3. Re-pilot with 1-2 participants
4. Take screenshots, add to `evidence/screenshots/`

### End of Week 10 (Package & Submit):
```bash
# Make packaging script executable
chmod +x package-submission.sh

# Run packaging script
./package-submission.sh

# Upload generated ZIP to Gradescope
```

---

## ğŸ¯ Quick Reference: File Purposes

| File | Purpose | When to Fill |
|------|---------|--------------|
| `protocol-tasks.md` | Task design + consent | Week 9 Lab 1 |
| `data/metrics.csv` | Raw pilot data (auto-generated) | Week 9 Lab 2 |
| `findings-table.csv` | Prioritized findings | Week 10 Lab 1 |
| `implementation-diffs.md` | Code fixes (before/after) | Week 10 Lab 2 |
| `verification.csv` | WCAG checklist + comparison | Week 10 Lab 2 |
| `evidence/README.md` | Privacy statement + index | Week 10 Lab 2 |
| `evidence/screenshots/` | Visual evidence | Throughout |
| `evidence/pilot-notes/` | Participant observations | Week 9 Lab 2 + Week 10 Lab 2 |

---

## âš ï¸ Common Mistakes to Avoid

1. **Forgetting to set session cookie** before each pilot
   ```javascript
   // Run this in browser console BEFORE each pilot:
   document.cookie = "sid=P1_a7f3; path=/";
   ```

2. **Not cropping screenshots** â†’ PII violation = potential fail
   - Always crop browser tabs, bookmarks, personal info

3. **Using real names** instead of P1_xxxx format
   - metrics.csv should NEVER have real names

4. **Skipping consent documentation**
   - Must record consent timestamps in consent-log.md

5. **Not linking evidence**
   - findings-table.csv must reference specific metrics.csv lines or pilot notes

---

## ğŸ†˜ Need Help?

- **Logger not working?** Check imports, ensure `data/` directory exists
- **Missing templates?** Scroll up to artifacts in this conversation
- **Confused about task design?** Review protocol-tasks.md example tasks
- **Not sure what to screenshot?** See annotations.csv for examples
- **Stuck on prioritization?** Use formula: Priority = (Impact + Inclusion) - Effort

---

## ğŸ“ Assessment Reminder

**Pass Criteria (must have ALL):**
- âœ… nâ‰¥2 participants
- âœ… 3+ findings with evidence
- âœ… 1-3 code fixes implemented
- âœ… 20 WCAG checks complete
- âœ… No PII violations
- âœ… No Level A WCAG violations remaining

**Due**: End of Week 10  
**Submission**: Upload ZIP to Gradescope

---

Good luck! ğŸš€

**Next step**: Fill in protocol-tasks.md with your actual tasks and job stories.